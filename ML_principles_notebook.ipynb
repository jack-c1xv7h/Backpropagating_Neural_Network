{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import csv\n",
    "\n",
    "class Neural_Network:\n",
    "    def __init__(self, definition_array, activation_function, batch_size=32):\n",
    "        self.definition = definition_array\n",
    "        self.activation_function = activation_function\n",
    "        self.batch_size = batch_size\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(len(definition_array)):\n",
    "            prev_layer = self.layers[i - 1] if i > 0 else None\n",
    "            prev_neuron_count = self.layers[i - 1].Neuron_count if i > 0 else 0\n",
    "            self.layers.append(Layer(prev_layer, definition_array[i], prev_neuron_count,\n",
    "                                     activation_function, batch_size))\n",
    "\n",
    "    def feedforward(self, input_batch):\n",
    "        self.layers[0].activation_values = input_batch\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.feedforward()\n",
    "        self.output_values = softmax(self.layers[-1].activation_values)\n",
    "\n",
    "    def backpropagate(self, target_batch):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            if i == len(self.layers) - 1:\n",
    "                output_error = layer.activation_values - target_batch\n",
    "                layer.delta = output_error * deriv_sigmoid(layer.activation_values)\n",
    "            else:\n",
    "                next_layer = self.layers[i + 1]\n",
    "                layer.delta = np.dot(next_layer.weights.T, next_layer.delta) * deriv_sigmoid(layer.activation_values)\n",
    "            if layer.prev_Layer is not None:\n",
    "                layer.weights -= np.dot(layer.delta, layer.inputs.T) * 0.005 / self.batch_size\n",
    "                layer.biases -= np.mean(layer.delta, axis=1, keepdims=True) * 0.5\n",
    "    \n",
    "    def train(self, datafile_path, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            with open(datafile_path, mode='r') as file:\n",
    "                datafile = csv.reader(file)\n",
    "                batch_inputs = []\n",
    "                batch_targets = []\n",
    "                correct_predictions = 0\n",
    "                for i, line in enumerate(datafile):\n",
    "                    target = np.zeros(10)\n",
    "                    target[int(line[0])] = 1.0\n",
    "                    inputs = np.array([float(line[i+1]) for i in range(784)])\n",
    "                    batch_inputs.append(inputs)\n",
    "                    batch_targets.append(target)\n",
    "                    if (i + 1) % self.batch_size == 0:\n",
    "                        batch_inputs = np.array(batch_inputs).T\n",
    "                        batch_targets = np.array(batch_targets).T\n",
    "                        self.feedforward(batch_inputs)\n",
    "                        correct_predictions += np.sum(np.argmax(self.output_values, axis=0) == np.argmax(batch_targets, axis=0))\n",
    "                        self.backpropagate(batch_targets)\n",
    "                        batch_inputs, batch_targets = [], []\n",
    "\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Correct Predictions: {correct_predictions}, Accuracy: {correct_predictions/600:.2f}%\")\n",
    "\n",
    "    def test(self, datafile_path):\n",
    "        with open(datafile_path, mode='r') as file:\n",
    "            datafile = csv.reader(file)\n",
    "            correct_predictions = 0\n",
    "            total_samples = 10000\n",
    "            for i, line in enumerate(datafile):\n",
    "                target = np.zeros(10)\n",
    "                target[int(line[0])] = 1.0\n",
    "                inputs = np.array([float(line[row * 28 + col + 1]) for row in range(28) for col in range(28)])\n",
    "                self.feedforward(inputs[:, np.newaxis])\n",
    "                if np.argmax(self.output_values) == int(line[0]):\n",
    "                    correct_predictions += 1\n",
    "                if (i + 1) == total_samples:\n",
    "                    break\n",
    "            accuracy = (correct_predictions / total_samples) * 100\n",
    "            print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, prev_Layer, Neuron_count, prev_Layer_Neuron_count, activation_function, batch_size):\n",
    "        self.prev_Layer = prev_Layer\n",
    "        self.Neuron_count = Neuron_count\n",
    "        self.activation_function = activation_function\n",
    "        self.batch_size = batch_size\n",
    "        self.inputs = None if prev_Layer is None else np.zeros((prev_Layer_Neuron_count, batch_size))\n",
    "        self.weights = default_rng(42).random((Neuron_count, prev_Layer_Neuron_count)) if prev_Layer else None\n",
    "        self.biases = np.zeros((Neuron_count, 1))\n",
    "        self.activation_values = np.zeros((Neuron_count, batch_size))\n",
    "        self.delta = np.zeros((Neuron_count, batch_size))\n",
    "\n",
    "    def feedforward(self):\n",
    "        if self.prev_Layer is None:\n",
    "            return\n",
    "        self.inputs = self.prev_Layer.activation_values\n",
    "        z = np.dot(self.weights, self.inputs) + self.biases\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            self.activation_values = sigmoid(z)\n",
    "        elif self.activation_function == \"relu\":\n",
    "            self.activation_values = relu(z)\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            self.activation_values = tanh(z)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=0, keepdims=True)\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeN = Neural_Network([784, 400, 10], \"sigmoid\", batch_size=32)\n",
    "NeN.train('mnist_train.csv', epochs=40)\n",
    "NeN.test('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] save1.txt\n",
      "[''] 0 1\n",
      "[''] 0 2\n",
      "[''] 0 3\n",
      "[''] 0 4\n",
      "[''] 0 5\n",
      "[''] 0 6\n",
      "[''] 0 7\n",
      "[''] 0 8\n",
      "[''] 0 9\n",
      "[''] 0 10\n",
      "[''] 0 11\n",
      "[''] 0 12\n",
      "[''] 0 13\n",
      "[''] 0 14\n",
      "[''] 0 15\n",
      "[''] 0 16\n",
      "[''] 0 17\n",
      "[''] 0 18\n",
      "[] save2.txt\n",
      "[''] 1 1\n",
      "[] save3.txt\n",
      "[''] 2 1\n",
      "[] save4.txt\n",
      "[''] 3 1\n",
      "[''] 3 2\n",
      "[''] 3 3\n",
      "[''] 3 4\n",
      "[''] 3 5\n",
      "[''] 3 6\n",
      "[''] 3 7\n",
      "[''] 3 8\n",
      "[''] 3 9\n",
      "[''] 3 10\n",
      "[''] 3 11\n",
      "[''] 3 12\n",
      "[''] 3 13\n",
      "[''] 3 14\n",
      "[''] 3 15\n",
      "[''] 3 16\n",
      "[''] 3 17\n",
      "[''] 3 18\n",
      "[''] 3 19\n",
      "[''] 3 20\n",
      "[''] 3 21\n",
      "[''] 3 22\n",
      "[''] 3 23\n",
      "[''] 3 24\n",
      "[''] 3 25\n",
      "[''] 3 26\n",
      "[] save5.txt\n",
      "[''] 4 1\n",
      "[''] 4 2\n",
      "[''] 4 3\n",
      "[''] 4 4\n",
      "[''] 4 5\n",
      "[''] 4 6\n",
      "[''] 4 7\n",
      "[''] 4 8\n",
      "[''] 4 9\n",
      "[''] 4 10\n",
      "[''] 4 11\n",
      "[''] 4 12\n",
      "[''] 4 13\n",
      "[''] 4 14\n",
      "[''] 4 15\n",
      "[''] 4 16\n",
      "[''] 4 17\n",
      "[''] 4 18\n",
      "[''] 4 19\n",
      "[''] 4 20\n",
      "[''] 4 21\n",
      "[''] 4 22\n",
      "[''] 4 23\n",
      "[''] 4 24\n",
      "[''] 4 25\n",
      "[''] 4 26\n",
      "[''] 4 27\n",
      "[''] 4 28\n",
      "[''] 4 29\n",
      "[''] 4 30\n",
      "[''] 4 31\n",
      "[''] 4 32\n",
      "[''] 4 33\n",
      "[''] 4 34\n",
      "[''] 4 35\n",
      "[''] 4 36\n",
      "[''] 4 37\n",
      "[''] 4 38\n",
      "[''] 4 39\n",
      "[''] 4 40\n",
      "[''] 4 41\n",
      "[''] 4 42\n",
      "[''] 4 43\n",
      "[''] 4 44\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "for i in range(5):\n",
    "    txt = open(\"save\" + str(i+1) + \".txt\")\n",
    "    textlength = len(txt.readlines())\n",
    "    labelarray = txt.readline(textlength)\n",
    "    labelarray = np.array(txt.readline(textlength).split(\", \"))\n",
    "    print(txt.readlines(), \"save\" + str(i+1) + \".txt\")\n",
    "    for v in range(textlength-1):\n",
    "        line = txt.readline(v+1)\n",
    "        linearray = np.array(line.split(\" \"))\n",
    "        print(linearray, i, v+1)\n",
    "     ##   linearray = linearray.astype(np.int32)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
